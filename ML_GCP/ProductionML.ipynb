{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProductionML.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatacrc/Notes/blob/master/ML_GCP/ProductionML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMvleCa129Y2",
        "colab_type": "text"
      },
      "source": [
        "##Production ML Systems\n",
        "Source: [Production Machine Learning Systems](https://www.coursera.org/learn/gcp-production-ml-systems/)\n",
        "\n",
        "###Course Outline\n",
        "1. Architecting Production ML Systems\n",
        "  1. Intro\n",
        "  1. Components of an ML system\n",
        "    1. Data Analysis and Validation\n",
        "    1. Data Transformation + Trainer\n",
        "    1. Tuner + Model Evaluation and Validation\n",
        "    1. Serving\n",
        "    1. Orchestration + workflow\n",
        "    1. Integrated Frontend + Storage\n",
        "  1. Design Decisions\n",
        "    1. Training Design Decisions\n",
        "    1. Serving Design Decisions\n",
        "  1. Serving on Cloud MLE\n",
        "    1. Lab\n",
        "  1. Designing an Architecture from Scratch\n",
        "1. Ingesting Data for Cloud-based analytics and ML\n",
        "  1. Intro\n",
        "  1. Data Scenarios\n",
        "    * Data On-Premise\n",
        "    * Large Datasets\n",
        "    * Data on Other Clouds\n",
        "    * Existing Databases\n",
        "  1. Demos\n",
        "    * Load data into BigQuery\n",
        "    * Automatic ETL Pipelines into GCP\n",
        "1. Designing Adaptable ML systems\n",
        "1. Designing High Performance ML Systems\n",
        "1. Hybrid ML Systems\n",
        "\n",
        "###Architecting Production ML Systems\n",
        "1. What's in a Production ML System\n",
        "  * Data Collection\n",
        "  * Data Verification\n",
        "  * Machine Resource Management\n",
        "  * Feature Extraction\n",
        "  * Process Management Tools\n",
        "  * Configuration\n",
        "  * Monitoring\n",
        "  * Analysis Tools\n",
        "  * Serving Infrastructure\n",
        "  * ML Code\n",
        "1. Training Design Decisions\n",
        "1. Serving Design Decisions\n",
        "1. Serving on CMLE (scalability)\n",
        "1. Designing an Architecture from Scratch\n",
        "\n",
        "![](https://drive.google.com/uc?id=1Z3J8cNIxAgssBpCSOgty-NB2TRDEwAzj)\n",
        "\n",
        "####Other Components of ML System\n",
        "\n",
        "![](https://drive.google.com/uc?id=1QgTOw5GRP2j7VLlyO05HNNPKNIQtvjpE)\n",
        "\n",
        "Reuse generic software frameworks\n",
        "* TensorFlow\n",
        "* TF Serving\n",
        "* Apache Spark\n",
        "* Apache Beam\n",
        "Use managed services\n",
        "* Cloud Dataproc\n",
        "* Cloud Dataflow\n",
        "* Cloud ML Engine\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QthLY0Yx5-WJ",
        "colab_type": "text"
      },
      "source": [
        "##The Components of an ML System\n",
        "\n",
        "###Data Ingestion\n",
        "\n",
        "![](https://drive.google.com/uc?id=1tNqCCmtoBl441XrlWaJIdo_Tww1ZGF-C)\n",
        "\n",
        "**Streaming Data Ingestion Pipeline Architecture**\n",
        "\n",
        "$\n",
        "\\left.\\begin{array}{ccc}\n",
        "{Applications} \\\\\n",
        "{Devices} \\\\\n",
        "{Databases}\n",
        "\\end{array}\\right\\} \\rightarrow\n",
        "\\left.\\begin{array}{ccc}\n",
        "{(Ingest)}\\\\\n",
        "{Cloud Pub/Sub}\n",
        "\\end{array}\\right\\} \\rightarrow\n",
        "\\left.\\begin{array}{ccc}\n",
        "{(Process)}\\\\\n",
        "{Cloud Dataflow}\n",
        "\\end{array}\\right\\} \\rightarrow \\left\\{ \n",
        "\\begin{array}{ccc}\n",
        "{(Analyze)}\\\\\n",
        "{Data Studio | Third Party Tools}\\\\\n",
        "{\\uparrow} \\\\\n",
        "{Cloud BigQuery} \\mapsto {Data Warehouse}\\\\ \n",
        "{Cloud MLE} \\mapsto {Predictive Analytics}\\\\\n",
        "{Cloud BigTable} \\mapsto {Caching \\& Serving} \n",
        "\\end{array}\\right.$\n",
        "\n",
        "####General Data Ingestion\n",
        "\n",
        "Involves taking Structured(BigQuery), Streaming(PubSub) and Unstructured(Cloud Storage) data like Text, Audio, Image, Video, and Tabular data to create TFRecord or CSV.\n",
        "\n",
        "Read$\\rightarrow$Process$\\rightarrow$Write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6smb8NTE92YY",
        "colab_type": "text"
      },
      "source": [
        "###Data Validation\n",
        "Is the data healthy or not?\n",
        "1. Is the new distribution similar enough to the old one? (5 number summary, modes, likelihood of distribution)\n",
        "1. Are all expected features present?\n",
        "1. Are any unexpected features present?\n",
        "1. Does the feature have the expected type?\n",
        "1. Does an expected proportion of the examples contain the feature?\n",
        "1. Do the examples have the expected number of values for feature?\n",
        "\n",
        "Data Validation Services\n",
        "  * Datalab\n",
        "  * DataStudio\n",
        "  * Cloud Reliability\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0DRt91F0CtH",
        "colab_type": "text"
      },
      "source": [
        "###Data Transformation\n",
        "For feature wrangling\n",
        "\n",
        "Data Transformation Services\n",
        "  * Dataflow\n",
        "  * Dataproc\n",
        "  * Dataprep\n",
        "\n",
        "###Trainer & Tuner\n",
        "It needs to support data and model parallelism and scale large number of workers, Monitor and log, experimentation, and Hyperparameter tuning.\n",
        "  * Cloud ML Engine(Managed service)\n",
        "    1. Scalable\n",
        "    1. Integrated with Tuner, Logging, Serving components\n",
        "    1. Experiment-oriented(A/B Testing)\n",
        "    1. Open\n",
        "  * GKE(Kubeflow)\n",
        "\n",
        "###Model Evaluation and Validation\n",
        "Tools:\n",
        "  * TFX Model Analysis\n",
        "A good model is hard to find\n",
        "1. model Safeness\n",
        "1. Prediction Quality\n",
        "\n",
        "Release, Develop, and Test Cycle\n",
        "###Serving\n",
        "Tools:\n",
        "  * ML Engine\n",
        "  * TF Serving(GKE)\n",
        "* Low latency\n",
        "* Highly efficient\n",
        "* Scale Horizontally\n",
        "* Reliable and robust\n",
        "* Easy to update versions (Multi-armed Mandit Testing)\n",
        "###Logging\n",
        "Tools:\n",
        "  * Cloud Reliability\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv8tmLiMhf5E",
        "colab_type": "text"
      },
      "source": [
        "###Shared Config and Utilities\n",
        "Quiz: If changes are made to the trainer, what component(s) might also need to change?\n",
        "Answer: Potentially all of them\n",
        "\n",
        "Configuration Remedies:\n",
        "1. Establish a common architecture for both R&D and production deployment\n",
        "1. Embed the teams together, so that engineering can influence the design of code from its inception\n",
        "\n",
        "**Orchestration** glues all the components together\n",
        "Tools:\n",
        "  * Cloud Composer (managed Apache Airflow)\n",
        "  * Argo (GKE)\n",
        "\n",
        "Steps to Compose a Workflow in Cloud Composer\n",
        "1. Define the Ops\n",
        "1. Arrange into a DAG\n",
        "1. Upload to Environment\n",
        "1. Explore DAG Run in Web UI\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdrTB1WujxDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A basic workflow\n",
        "\n",
        "# BigQuery training data query\n",
        "t1 = BigQueryOperator(params)\n",
        "\n",
        "# BigQuery training data export to GCS\n",
        "t2 = BigQueryToCloudStorageOperatot(params)\n",
        "\n",
        "# ML Engine training job\n",
        "t3 = MLEngineTrainingOperator(params)\n",
        "\n",
        "# App Engine deploy new version\n",
        "t4 = AppEngineVersionOperator(params)\n",
        "\n",
        "# Etsablish dependencies\n",
        "t1 >> t2 >> t3 >> t4 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrB_LJPHkluU",
        "colab_type": "text"
      },
      "source": [
        "###Integrated Frontend\n",
        "Tools:\n",
        "  * ML Engine\n",
        "  * TensorBoard\n",
        "\n",
        "http://projector.tensorflow.org/\n",
        "\n",
        "Debug TF in real-time line by line execution.\n",
        "\n",
        "###Pipeline Storage\n",
        "Tools:\n",
        "  * GCS Google Cloud Storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8LGIk6n2Gz",
        "colab_type": "text"
      },
      "source": [
        "##Training Design Decision\n",
        "Static Vs Dynamic Training\n",
        "\n",
        "In static we do top to bottom only once where as in Dynamic traing we do it repeatedly.\n",
        "  * Acquire Data\n",
        "  * Transform Data\n",
        "  * Train model\n",
        "  * Test model\n",
        "  * Deploy Model\n",
        "\n",
        "Statically Trained Models|Dynamically Trained Models\n",
        "---|---\n",
        "Trained once, offline|Add training data over time\n",
        "Easy to build and test|Engineering is harder have to do progressive validation\n",
        "Easy to let become stale | Regularly sync out updated version. Will adapt to changes\n",
        "\n",
        "![](https://drive.google.com/uc?id=1BpMDbQDmlkWHMfBAGnzC48PKVlLVYkoW)\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?id=1rGy-_MB2P1FnQGiap88PZ_F4Cz3UspgP)\n",
        "\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?id=1W2F3j3pktQrhDGLc702lk92_s-Pkjp_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt6jUyPvtxa_",
        "colab_type": "text"
      },
      "source": [
        "##Serving Design Decisions\n",
        "\n",
        "###Static Vs Dynamic Serving\n",
        "\n",
        "Static serving uses lookup table with the pre-computed labels to serve the prediction request.\n",
        "\n",
        "####Architecting a Static Serving Model\n",
        "1. Change Cloud MLE from online to batch prediction job\n",
        "1. Model accpets and passes keys as input\n",
        "1. Write predictions to a data warehouse(e.g. BigQuery)\n",
        "\n",
        "Where as in Dynamic serving runs the model to generate the labes on demand to serve the prediction request.\n",
        "\n",
        "Static|Dynamic\n",
        "---|---\n",
        "Higher storage cost|lower storage cost\n",
        "low, fixed latency | variable latency\n",
        "low maintenance|hiher maintenance\n",
        "space intensive|Compute intensive\n",
        "\n",
        "* **Peakedness** is how concentrated the distribution is\n",
        "* **Cardinality** (size of the input space) is the number of values in the set\n",
        "\n",
        "Cardinality is low use static serving.\n",
        "\n",
        "Hybrid solutions optimize for both types of prediction workloads most frequest results cached and tail computed on-demand.\n",
        "\n",
        "Problem|Inference Style\n",
        "---|---\n",
        "Spam| Dynamic\n",
        "Voice to Text | Dynamic/Hybrid\n",
        "Shopping ad conversion rate | Static\n",
        "\n",
        "```\n",
        "gcloud ml-engine predict --model $MODEL_NAME \\\n",
        "                    --version $VERSION_NAME \\\n",
        "                    --json-instances $INPUT_DATA_FILE\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwPaDK10xzKP",
        "colab_type": "text"
      },
      "source": [
        "###Lab: Invoke ML predictions with Google App Engine(GAE)\n",
        "\n",
        "![](https://drive.google.com/uc?id=1Gdm2SibRslIJC46gFga_zGJF_VvZ80U4)\n",
        "\n",
        "Repo:\n",
        "git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n",
        "\n",
        "1. Build an App on GAE that makes REST calls(Web API requests) to CMLE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX5CPzNtyAEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Use “gcloud config set project [PROJECT_ID]” to change to a different project.\n",
        "student_02_febba43ae9df@cloudshell:~ (qwiklabs-gcp-02-3e892ea7122e)$ gcloud auth list\n",
        "           Credentialed Accounts\n",
        "ACTIVE  ACCOUNT\n",
        "*       student-02-febba43ae9df@qwiklabs.net\n",
        "\n",
        "To set the active account, run:\n",
        "    $ gcloud config set account `ACCOUNT`\n",
        "\n",
        "student_02_febba43ae9df@cloudshell:~ (qwiklabs-gcp-02-3e892ea7122e)$ gcloud config list project\n",
        "[core]\n",
        "project = qwiklabs-gcp-02-3e892ea7122e\n",
        "\n",
        "Your active configuration is: [cloudshell-29148]\n",
        "\n",
        "Start Cloud Shell\n",
        "Activate Google Cloud Shell\n",
        "Google Cloud Shell is a virtual machine that is loaded with development tools. It offers a persistent 5GB home directory and runs on the Google Cloud. Google Cloud Shell provides command-line access to your GCP resources.\n",
        "\n",
        "In GCP console, on the top right toolbar, click the Open Cloud Shell button.\n",
        "\n",
        "Cloud Shell icon\n",
        "\n",
        "Click Continue. \n",
        "\n",
        "It takes a few moments to provision and connect to the environment. When you are connected, you are already authenticated, and the project is set to your PROJECT_ID. For example:\n",
        "\n",
        "Cloud Shell Terminal\n",
        "\n",
        "gcloud is the command-line tool for Google Cloud Platform. It comes pre-installed on Cloud Shell and supports tab-completion.\n",
        "\n",
        "You can list the active account name with this command:\n",
        "\n",
        "gcloud auth list\n",
        "\n",
        "Output:\n",
        "\n",
        "Credentialed accounts:\n",
        " - <myaccount>@<mydomain>.com (active)\n",
        "Example output:\n",
        "\n",
        "Credentialed accounts:\n",
        " - google1623327_student@qwiklabs.net\n",
        "You can list the project ID with this command:\n",
        "\n",
        "gcloud config list project\n",
        "\n",
        "Output:\n",
        "\n",
        "[core]\n",
        "project = <project_ID>\n",
        "Example output:\n",
        "\n",
        "[core]\n",
        "project = qwiklabs-gcp-44776a13dea667a6\n",
        "Full documentation of gcloud is available on Google Cloud gcloud Overview.\n",
        "Copy trained model\n",
        "Step 1\n",
        "Set necessary variables and create a bucket:\n",
        "\n",
        "REGION=us-central1\n",
        "BUCKET=$(gcloud config get-value project)\n",
        "TFVERSION=1.7\n",
        "gsutil mb -l ${REGION} gs://${BUCKET}\n",
        "Step 2\n",
        "Copy trained model into your bucket:\n",
        "\n",
        "gsutil -m cp -R gs://cloud-training-demos/babyweight/trained_model gs://${BUCKET}/babyweight\n",
        "Deploy trained model\n",
        "Step 1\n",
        "Set necessary variables:\n",
        "\n",
        "MODEL_NAME=babyweight\n",
        "MODEL_VERSION=ml_on_gcp\n",
        "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/babyweight/export/exporter/ | tail -1)\n",
        "Step 2\n",
        "Deploy trained model:\n",
        "\n",
        "gcloud ai-platform models create ${MODEL_NAME} --regions $REGION\n",
        "gcloud ai-platform versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION\n",
        "Code for your frontend\n",
        "Step 1\n",
        "Clone the course repository:\n",
        "\n",
        "cd ~\n",
        "git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n",
        "Step 2\n",
        "You can use the Cloud Shell code editor to view and edit the contents of these files.\n",
        "\n",
        "Click on the (b8ebde10ba2a31c8.png) icon on the top right of your Cloud Shell window to launch Code Editor.\n",
        "\n",
        "Once launched, navigate to the ~/training-data-analyst/courses/machine_learning/deepdive/06_structured/labs/serving directory.\n",
        "\n",
        "Step 3\n",
        "Open the application/main.pyand application/templates/form.html files and notice the #TODOs within the code. These need to be replaced with code. The next section tells you how.\n",
        "\n",
        "Modify main.py\n",
        "Step 1\n",
        "Open the main.py file by clicking on it. Notice the lines with # TODO for setting credentials and the api to use.\n",
        "\n",
        "Set the credentials to use Google Application Default Credentials (recommended way to authorize calls to our APIs when building apps deployed on AppEngine):\n",
        "\n",
        "credentials = GoogleCredentials.get_application_default()\n",
        "Specify the api name (ML Engine API) and version to use:\n",
        "\n",
        "api = discovery.build('ml', 'v1', credentials=credentials)\n",
        "Step 2\n",
        "Scroll further down in main.py and look for the next #TODO in the method get_prediction(). In there, specify, using the parent variable, the name of your trained model deployed on Cloud MLE:\n",
        "\n",
        "parent = 'projects/%s/models/%s' % (project, model_name)\n",
        "Step 3\n",
        "Now that you have all the pieces for making the call to your model, build the call request by specifying it in the prediction variable:\n",
        "\n",
        "prediction = api.projects().predict(body=input_data, name=parent).execute()\n",
        "Step 4\n",
        "The final #TODO (scroll towards bottom) is to get gestation_weeks from the form data and cast into a float within the features array:\n",
        "\n",
        "features['gestation_weeks'] = float(data['gestation_weeks'])\n",
        "Step 5\n",
        "Save the changes you made using the File > Save button on the top left of your code editor window.\n",
        "\n",
        "3b0e6c092072fec5.png\n",
        "\n",
        "Modify form.html\n",
        "form.html is the front-end of your app. The user fills in data (features) about the mother based on which we will make the predictions using our trained model.\n",
        "\n",
        "Step 1\n",
        "In code editor, navigate to the application/templates directory and click to open the form.html file.\n",
        "\n",
        "Step 2\n",
        "There is one #TODO item here. Look for the div segment for Plurality and add options for other plurality values (2, 3, etc).\n",
        "\n",
        "<md-option value=\"2\">Twins</md-option>\n",
        "<md-option value=\"3\">Triplets</md-option>\n",
        "Step 3\n",
        "Save the changes you made using the File > Save button on the top left of your code editor window.\n",
        "\n",
        "Deploy and test your app\n",
        "Step 1\n",
        "In Cloud Shell, run the deploy.sh script to install required dependencies and deploy your app engine app to the cloud.\n",
        "\n",
        "cd training-data-analyst/courses/machine_learning/deepdive/06_structured/labs/serving\n",
        "./deploy.sh\n",
        "Note: Choose a region for App Engine when prompted and follow the prompts during this process\n",
        "\n",
        "Step 2\n",
        "Go to the url https://<PROJECT-ID>.appspot.com and start making predictions.\n",
        "\n",
        "Note: Replace <PROJECT-ID> with your Project ID.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RUilE7x7eaX",
        "colab_type": "text"
      },
      "source": [
        "###Lab: Build a system that predicts the traffic levels on roads.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbhVoj2x-2OF",
        "colab_type": "text"
      },
      "source": [
        "##Ingesting Data\n",
        "![](https://drive.google.com/uc?id=19likwvnYXzUbdswOd1Tkn710LtHMckKn)\n",
        "\n",
        "Data On-Premise\n",
        "\n",
        "\n",
        "```\n",
        "# include -m for multi-threading\n",
        "gsutil -m cp -r [src dir] gs://[bucket_name]\n",
        "```\n",
        "\n",
        "![](https://drive.google.com/uc?id=1DM9JVVmMjShYsC5QF-6mJcUx_XmQvrBJ)\n",
        "\n",
        "Large Datasets\n",
        "* about 60TB data\n",
        "Transfer appliance\n",
        "\n",
        "Cloud-to-Cloud Transfer\n",
        "\n",
        "Existing Databases\n",
        "![](https://drive.google.com/uc?id=1GZGNi_EXQOrceurnHk-yi1yFYLeKahQd)\n",
        "\n",
        "Ingest data into BigQuery\n",
        "* Types supported\n",
        "  * CSV, JSON, AVRO, ORC, Parquet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmlqaYEHIDa5",
        "colab_type": "text"
      },
      "source": [
        "##Automatic ETL Pipelines into GCP\n",
        "\n",
        "Managed Airflow:\n",
        "\n",
        "ETL Pattern 1: Push Solution Architecture (best for on-demand)\n",
        "\n",
        "![](https://drive.google.com/uc?id=17D21dX8W_NwbHmEOTXLYA_xlcoRs5OHa)\n",
        "\n",
        "ETL Pattern2 : [Pull Solution Architecture](https://cloud.google.com/blog/products/gcp/designing-etl-architecture-for-a-cloud-native-data-warehouse-on-google-cloud-platform)\n",
        "\n",
        "[Datalake](https://cloud.google.com/solutions/build-a-data-lake-on-gcp)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rckhBxk2OGIc",
        "colab_type": "text"
      },
      "source": [
        "#WEEK2\n",
        "\n",
        "##Designing Adaptable ML Systems\n",
        "\n",
        "Objectives:\n",
        "1. Recognize variaous data dependencies.\n",
        "1. Make cost-conscious engineering decisions\n",
        "1. Mitigate model pollution\n",
        "1. Implement a pipeline that is immune to one type of dependency\n",
        "1. Debug the causes of observed model behavior\n",
        "\n",
        "Modularity and Dependency management became easier with [maven](https://pypi.org/project/maven/), [gretle](https://pypi.org/project/gretel/0.0.8/), and pip.\n",
        "Containers eliminate infrastructure dependecies.\n",
        "\n",
        "Mismanaged Dependecies are costly:\n",
        "1. Losses in prediction quality\n",
        "1. Decreases to system stability\n",
        "1. Decreases in team productivity\n",
        "\n",
        "###Adapting to Data\n",
        "\n",
        "1. Changing Distributions\n",
        "  * Monitor descriptive statistics for your inputs and outputs\n",
        "  * Monitor your residuals as a function of your inputs\n",
        "  * Use custom weights in your loss function to emphasize data recency\n",
        "  * Use dynamic training architecture and regularly retrain your model\n",
        "\n",
        "###Training-Serving Skew\n",
        "1. A discrepency between how you handle data in the training and serving pipelines\n",
        "1. A change in the data between when you train and when you serve\n",
        "1. A feedback loop between your model and your algorithm\n",
        "\n",
        "How Code can Create Training/Serving Skew\n",
        "* Different library versions that are functionally equivalent but optimized differently\n",
        "* Different library versions that are not functionally equivalent\n",
        "* Re-implemented functions\n",
        "\n",
        "Lab:\n",
        "Training Data is Batch and Serving data is Streaming.\n",
        "![](https://drive.google.com/uc?id=1CB7PspWfvMZJv1mT9IiXT-eG5yFGIo3j)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhjLaq_-hSG0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "student_03_8c0375482826@cloudshell:~ (qwiklabs-gcp-03-bb0ca9c3aac2)$ gcloud ai-platform models create ${MODEL_NAME} --regions $REGION             \n",
        "Created ml engine model [projects/qwiklabs-gcp-03-bb0ca9c3aac2/models/babyweight].\n",
        "student_03_8c0375482826@cloudshell:~ (qwiklabs-gcp-03-bb0ca9c3aac2)$ gcloud ai-platform versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION\n",
        "Creating version (this might take a few minutes)......done.\n",
        "student_03_8c0375482826@cloudshell:~ (qwiklabs-gcp-03-bb0ca9c3aac2)$ cd ~\n",
        "student_03_8c0375482826@cloudshell:~ (qwiklabs-gcp-03-bb0ca9c3aac2)$ git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n",
        "Cloning into 'training-data-analyst'...\n",
        "remote: Enumerating objects: 60, done.\n",
        "remote: Counting objects: 100% (60/60), done.\n",
        "remote: Compressing objects: 100% (49/49), done.\n",
        "remote: Total 29663 (delta 30), reused 27 (delta 11), pack-reused 29603\n",
        "Receiving objects: 100% (29663/29663), 279.01 MiB | 28.57 MiB/s, done.\n",
        "Resolving deltas: 100% (18288/18288), done.\n",
        "student_03_8c0375482826@cloudshell:~ (qwiklabs-gcp-03-bb0ca9c3aac2)$\n",
        "student_03_8c0375482826@cloudshell:~ (qwiklabs-gcp-03-bb0ca9c3aac2)$\n",
        "student_03_8c0375482826@cloudshell:~ (qwiklabs-gcp-03-bb0ca9c3aac2)$ cd ~/training-data-analyst/courses/machine_learning/deepdive/06_structured/labs/serving\n",
        "student_03_8c0375482826@cloudshell:~/training-data-analyst/courses/machine_learning/deepdive/06_structured/labs/serving (qwiklabs-gcp-03-bb0ca9c3aac2)$ ./what_to_fix.sh\n",
        "./application/main.py:credentials = # TODO\n",
        "./application/main.py:api = # TODO\n",
        "./application/main.py:  parent = # TODO\n",
        "./application/main.py:  prediction = # TODO\n",
        "./application/main.py:  features['gestation_weeks'] = # TODO: get gestation_weeks and cast to float\n",
        "./application/templates/form.html:            <!-- TODO: add options for other plurality values -->\n",
        "./pipeline/src/main/java/com/google/cloud/training/mlongcp/BabyweightMLService.java:  private static final String PROJECT = \"cloud-training-demos\"; // TODO: put in your project name here\n",
        "./pipeline/src/main/java/com/google/cloud/training/mlongcp/BabyweightMLService.java:  private static String       VERSION = \"ml_on_gcp\"; // TODO:put in your version name here\n",
        "\n",
        "```"
      ]
    }
  ]
}