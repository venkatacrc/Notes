{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Probability.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatacrc/Notes/blob/master/Probability/Probability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcuer3NzUtp9",
        "colab_type": "text"
      },
      "source": [
        "#Probablity Fundamentals\n",
        "\n",
        "Probability Fundamentals AWS Machine Learning Course from Brent Werness.\n",
        "\n",
        "---\n",
        "Probability enables machines to manage outcomes and outputs.\n",
        "\n",
        "Topics:\n",
        "* Axioms of probability\n",
        "* Probability represented using Venn diagrams\n",
        "* Conditional probability\n",
        "* Baye's rule\n",
        "* Independent events and notation\n",
        "* Random variables\n",
        "* Chebyshev's inequality\n",
        "* Entropy\n",
        "* Continuous random variables and probability density function\n",
        "* The gaussian curve\n",
        "* Building machine learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJCo1OfCdRz2",
        "colab_type": "text"
      },
      "source": [
        "## Intuition\n",
        "Probability theory is used to model systems where the outcomes are either:\n",
        "* inherently random (or)\n",
        "* simply **too complex** to be completely known\n",
        "\n",
        "### Motivating example: Rolling a die\n",
        "When you roll a die, you could **in theory** know enough about it to perfectly predict the outcome will be (by modeling force exerted, angle of projection, velocities, material and shape of die, friction and surface type etc.). However this **can never be done in practice**. In order to perfectly predict we have to know exactly what is going on, but we can't do that. We think the model in our minds the dice roll is random and each side is equally likely. So we can summarize the dice roll as I don't know what the answer is so I will assume to be random over set if all possible outcomes.\n",
        "\n",
        "When you are looking at some possible event, the **probability** of the event encodes the fraction of **time** that the outcome would occur with **repeated experiments**.\n",
        "\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zke81YMiWvj",
        "colab_type": "text"
      },
      "source": [
        "## Probability Terminology\n",
        "\n",
        "###Coin Flip Example\n",
        "Suppose I flip three coins. What is the probability that I get **exactly** two heads?\n",
        "There are 3 combinations that can produce exactly 2 heads. Those are HHT, HTH, and THH 3 possibilities out of 8 resulting in the probability 3/8.\n",
        "###Definitions\n",
        "* Outcome\n",
        "> A single possibility from the experiment.\n",
        "* Sample space\n",
        "> The set of all possible outcomes.\n",
        "> $\\Omega = \\{HHH,HHT, HTH, HTT, THH, THT, TTH, TTT\\}$\n",
        "* Event\n",
        "> Is a subset of your sample space that corresponds to something you can observe with yes/no answer.\n",
        "> $E=\\{ Exactly\\ 2\\ heads\\} = \\{HHT, HTH, THH\\}$\n",
        "* Probability\n",
        "> Fraction of an experiment where an event occurs.\n",
        ">$\\mathbb{P}\\{E\\} \\longleftarrow$ Probability (Fraction of times) we see the event E. $\\mathbb{P}\\{E\\} \\in[0,1]$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fogItO_u5lRz",
        "colab_type": "text"
      },
      "source": [
        "## Axioms of Probability\n",
        "###Axiom #1\n",
        "The fraction of the time an event occurs is between 0 and 1.\n",
        ">$\\mathbb{P}\\{E\\} \\in[0,1]$\n",
        "###Axiom #2\n",
        "Something always happens. Probability of observing one of the possible outcomes is equal to 1. \n",
        ">$\\mathbb{P}\\{\\Omega\\}$ = 1\n",
        "###Axiom #3\n",
        "If two events can't happen at the same time, then the fraction of the time that at least *one* of them occurs is the sum of the fraction of the time either one occurs separately.\n",
        "> Example: Two disjoint events E1 = {First coin is H} and E2 = {First coin is T}\n",
        "> $E1\\ \\cap\\ E2 = \\Phi$ (set with no elements)\n",
        "> $\\mathbb{P}\\{E1\\ \\cup\\ E2\\} = \\mathbb{P}\\{E1\\} + \\mathbb{P}\\{E2\\}$ = 1\n",
        "This Axiom works for any number of events (including coutably infinite)\n",
        ">$\\mathbb{P}\\{\\bigcup\\limits_{i} E_{i}\\} = \\sum\\limits_{i}\\mathbb{P}\\{E_{i}\\}$\n"
      ]
    }
  ]
}