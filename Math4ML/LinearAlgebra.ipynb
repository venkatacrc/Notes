{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearAlgebra.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatacrc/Notes/blob/master/Math4ML/LinearAlgebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77r2VfgLEKhE",
        "colab_type": "text"
      },
      "source": [
        "# Linear Algebra\n",
        "Source: AWS Machine Learning Course from Brent Werness.\n",
        "\n",
        "The Machine Learning Pipeline in Mathematics\n",
        "\n",
        "In practice, Machine Learning is a collection **methods** that allow the extraction of **rules** or **patterns** from data rather than explicit construction from a programmer.\n",
        "\n",
        "###Pipeline\n",
        "\n",
        "Phase1: Data Preprocessing\n",
        ">This is where you format data in a way algorithms can ingest. Uses linear algebra.\n",
        "* Collection\n",
        "* Formating\n",
        "* Labeleing\n",
        "\n",
        "Phase2: Feature Engineering & Selection\n",
        "> This is where you transform data to make it easy for algorithms to understand. You can use linear algebra to perform **multiplication** and **addition** on:\n",
        "* Vectors\n",
        "* Matrices\n",
        "\n",
        "Phase3: Modeling\n",
        ">This is where you define the problem in a way the algorithm can optimize. The goal is to learn what is drving observed events. Represented using Loss functions, probability of data being generated, uses norms to produce how close it is to the true value to the observed, and informed by statistics\n",
        "* Geometry\n",
        "* Probablity\n",
        "* Norms\n",
        "* Statistics\n",
        "\n",
        "Phase4: Optimization\n",
        ">To fit your data as best as possible. This is where you iterate until certain conditions are met, and then you choose the best model. Uses vector calculus (functions and derivatives) and in practice uses numerical methods such as gradient descent.\n",
        "* Training phase\n",
        "* Data evaluation (validation)\n",
        "* Predictions (real-world)\n",
        "\n",
        "* Vectors and Linear Spaces\n",
        "  * Vector representation\n",
        "  * norms (L1, L2, L$\\infty$)\n",
        "  * inner products\n",
        "  * Linear independence\n",
        "  * Orthogonality\n",
        "  * Hyperplanes\n",
        "  * Subspaces\n",
        "* Matrix Theory\n",
        "  * Basic matrix operations\n",
        "  * Matrices as linear operators, rank\n",
        "  * Span , Linear dependence\n",
        "  * Solving systems of linear equations\n",
        "\n",
        "##Vectors and Matrices\n",
        "* Column vectors\n",
        "* Row vectors\n",
        "* Matrices\n",
        "> can represent a collection of data points\n",
        "  * Addition and the Zero vector\n",
        "  * Scalar Multiplication\n",
        "  * Transpose\n",
        "\n",
        "###Geometry of Column Vectors\n",
        "* Vectors as Directions\n",
        "* Scalar Multiplication\n",
        "> Stretching the vectors\n",
        "\n",
        "* Addition as Displacement\n",
        "> Concatenation of vectors\n",
        "\n",
        "* Subtraction as Mapping\n",
        "> Takes one vector to another\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eshzpzABGJfj",
        "colab_type": "text"
      },
      "source": [
        "###Measures of Magnitude\n",
        "\n",
        "* Definitions of Norms\n",
        ">are a measure of distance\n",
        "\n",
        "* Norm Properties\n",
        "> 1. All distances are non-negative $\\Vert \\overrightarrow v \\Vert \\ge 0$\n",
        "  1. Distances multiply with scalar multiplication $\\Vert a \\overrightarrow v \\Vert = |a|.\\Vert \\overrightarrow v \\Vert$\n",
        "  1. Triangle Inequality: If I travel from **A** to **B** then **B** to **C**, that is at least as far as going from **A** to **C**. $\\Vert \\overrightarrow v + \\overrightarrow w\\Vert \\le \\Vert \\overrightarrow v \\Vert + \\Vert \\overrightarrow w \\Vert$\n",
        "* Types of Norms\n",
        "  * Euclidean Norm\n",
        "  >$\\Vert \\overrightarrow v \\Vert_2 = \\sqrt { v_1^2 + \\cdots + v_n^2} = \\sqrt {\\sum\\limits_{i=1}^{n}v_i^2}$\n",
        "\n",
        "  * $L_p$-Norm\n",
        "  > for $p \\ge 1$ all the axioms hold\n",
        "  >$\\Vert \\overrightarrow v \\Vert_p =  \\big({\\sum\\limits_{i=1}^{n}|v_i|^p\\big)^{\\frac{1}{p}}}, |v_i|^p \\ge 0$\n",
        "\n",
        "  * $L_1$-Norm\n",
        "  > Taxicab Metric, Manhattan Norm Only allowed to travel in the restricted grid instead of diagonal:\n",
        "  > $L_p$-Norm for p=1\n",
        "  > $\\Vert \\overrightarrow v \\Vert_1 =  \\big({\\sum\\limits_{i=1}^{n}|v_i|\\big)}$\n",
        "\n",
        "  * $L_{\\infty}$-Norm\n",
        "  > $L_p$-Norm for $p\\rightarrow \\infty$\n",
        "  > $\\Vert \\overrightarrow v \\Vert_\\infty =  \\lim \\limits_{p\\rightarrow \\infty} \\Vert \\overrightarrow v \\Vert_p = \\lim \\limits_{p\\rightarrow \\infty}\\big({\\sum\\limits_{i=1}^{n}|v_i|^p\\big)^{\\frac{1}{p}}}$\n",
        "\n",
        "   > zooms in on the largest components, maximum displacement in any direction. Used for worst case analysis.\n",
        "\n",
        "   > $\\Vert \\overrightarrow v \\Vert_\\infty =  \\max \\limits_ i |v_i|$\n",
        "\n",
        "  * Geometry of Norms\n",
        "    * $L_2$-Norm = Circle\n",
        "    * $L_1$-Norm = Diamond inside Circle\n",
        "    * $L_\\infty$-Norm = Unit Square \n",
        "  * A special case: The $L_0$-Norm\n",
        "  > Despite the name, this is **not** a norm.\n",
        "  >$\\Vert \\overrightarrow v \\Vert_0$ = number of non-zero elements of the vector $\\overrightarrow v$. \n",
        "  >$\\lim \\limits_{p\\rightarrow 0} = \\Vert \\overrightarrow v \\Vert_p^p = \\Vert \\overrightarrow v \\Vert_0$\n",
        "\n",
        "    > for a $\\ne$ 0 $\\Vert a\\overrightarrow v \\Vert_0 = \\Vert \\overrightarrow v \\Vert_0$ this is not a real norm. But used to measure the sparsity of a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkVPnjqqT-cO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "78582a18-3763-4016-ec8c-73568b698b87"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "v = [1, 2, 3]\n",
        "A = [[1, 2, 3], [-1, 0, 1], [1, 1, 1]]\n",
        "\n",
        "print('L1-norm = {}'.format(np.linalg.norm(v, ord=1)))\n",
        "print('L2-norm = {}'.format(np.linalg.norm(v, ord=2)))\n",
        "print('Linf-norm = {}'.format(np.linalg.norm(v, ord=np.inf)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1-norm = 6.0\n",
            "L2-norm = 3.7416573867739413\n",
            "Linf-norm = 3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KguwbGloU5Zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca16ecda-d71a-44b7-f076-361715cd7eb6"
      },
      "source": [
        "# Python, in general, takes a different convention for matrix norms. Most will not do what you think they will from our notation. \n",
        "# However, you can type the following for L2 norm. \n",
        "print(np.linalg.norm(A))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.358898943540674\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}