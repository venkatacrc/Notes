{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MachineLearning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatacrc/Notes/blob/master/MachineLearning/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTdQ9eOMN339",
        "colab_type": "text"
      },
      "source": [
        "## Machine Learning Interview Questions\n",
        "source: Andrew Ng's Machine Learning https://www.coursera.org/learn/machine-learning\n",
        "\n",
        "**What is Machine Learning?**\n",
        "Arthur Samuel: “The field of study that gives computers the ability to learn without being explicitly programmed.”\n",
        "Tom Mitchell: “A computer program is said to learn from experience E wrt some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”\n",
        "\n",
        "**What are the different classes of Machine Learning?**\n",
        "Supervised, Unsupervised, and Reinforcement Learning\n",
        "\n",
        "*Supervised Learning(SL):* We are given a data set with input and correct output.\n",
        "Regression: map input variables to some continuous function e.g. predict the age of a person\n",
        "Classification: map input variables to into discrete categories e.g.: tumor prediction\n",
        "\n",
        "*Unsupervised Learning(UL):*\n",
        "We can derive the structure from data by clustering the data based on relationships among the variables\n",
        "With UL there is no feedback based on the prediction results\n",
        "Non-clustering: “The cocktail party algorithm”\n",
        "\n",
        "**How do you represent a Model?**\n",
        "\n",
        "Training set with m training examples and n features\n",
        ">$(x_{(j)}^{(i)} ,y_{(j)}^{(i)}); i = 1, …, m; j = 1,...,n$\n",
        "\n",
        ">$X = Y = \\mathbb{R}$\n",
        "\n",
        "*Hypothesis function* h : X -> Y\n",
        ">$h_\\theta(x) =\n",
        " \\begin{pmatrix}\n",
        "  \\theta_0&\\theta_1&\\cdots&\\theta_n\n",
        " \\end{pmatrix}\n",
        " \\begin{pmatrix}\n",
        "  x_{0,0} &\\cdots&x_{0,m} \\\\\n",
        "  x_{1,0} &\\cdots&x_{1,m}  \\\\\n",
        "  \\vdots   &\\vdots&\\vdots \\\\\n",
        "  x_{n,0} &\\cdots&x_{n,m} \\\\ \n",
        " \\end{pmatrix} = \\theta^Tx\n",
        " $\n",
        "\n",
        "*Cost function:*\n",
        "Measure the accuracy of our hypothesis function by using a cost function. The objective is to minimize the cost function.\n",
        "MSE or Squared error function \n",
        ">$J(\\theta) = \\frac{mean\\ of\\ the\\ squares\\ of\\ the\\ error}{2} = \\frac{1}{2m}\\sum\\limits_{i=1}^m(h_\\theta(x_i) - y_i)^2$\n",
        "\n",
        "**What is Gradient Descent?**\n",
        "\n",
        "Gradient descent algorithm helps to estimate the parameters in the hypothesis function. The way we perform this operation is by taking the derivative of the cost function and modify the parameters based on the slope of tangent line to a function (derivative) at that point. It will give us the direction to move and steps down the cost function in the direction of steepest descent.\n",
        ">repeat until convergence: \n",
        "{ \n",
        "$\\theta_j := \\theta_j - \\alpha \\frac{1}{m}\\sum\\limits_{i=1}^{m}\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,..)$ \n",
        "} where $\\alpha$ = learning rate\n",
        "\n",
        "**What is batch gradient descent?**\n",
        "Batch gradient descent looks at every example in the entire training set.\n",
        "\n",
        "**What is feature scaling?**\n",
        "Feature scaling involves dividing the input values by the range(i.e. the maximum value minus the minimum value), resulting in a new range of just 1.\n",
        "\n",
        "**What is mean normalization?**\n",
        "mean normalization involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero.\n",
        "$x_i := \\frac{x_i - \\mu_i}{s_i}$; $s_i$ = (max - min) or standard deviation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spcCZs60N1eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}